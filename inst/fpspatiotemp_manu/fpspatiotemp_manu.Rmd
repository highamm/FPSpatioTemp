---
title: |
  An Application of Spatiotemporal Modeling to Finite Population Abundance Prediction
type: ARTICLE TEMPLATE
author:
  - name: Matt Higham
    affil: a
    email: mhigham@stlawu.edu
  - name: Carly Hammond, John Merickel, Jeff Wells
    affil: b
    email: fill these in later
  - name: add more
    affil: c, \dagger, \ddagger
    email: leutnant@fh-muenster.de
affiliation:
  - num: a
    address: |
      St. Lawrence University
      Canton, NY 13617
  - num: b
    address: |
      fill in later
  - num: c
    address: |
      fill in later
bibliography: interactcadsample.bib
# appendix: appendix.tex
abstract: |
  Insert abstract here.
keywords: |
  spatial; temporal; kriging; 
header-includes: |
  \usepackage{hyperref}
  \usepackage[utf8]{inputenc}
  \def\tightlist{}
output: rticles::tf_article
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

\section{Introduction}

\subsection{Motivation}

Moose surveys in Alaska and western Canada are often performed annually in many regions. The primary goal of these surveys is to predict moose abundance, the total number of moose, in the region. Because of time and money constraints, only some areas (sites) in the region of interest are selected to be in the survey. Biologists fly to these selected sites, count the number of moose, and can then use a spatial statistical model to find a prediction for the finite abundance for that year [@ver2008spatial]. 

Though these surveys are annual, each survey is analysed completely independently of surveys from previous years [e.g. @gasaway1986estimating; @kellie_geospatial_2006; @boertje2009managing; @peters2014contrasting]. For example, a model for a survey conducted in the year 2019 only uses counts on sites that were sampled in that year. However, using counts from previous years in a model that incorporates both spatial and temporal correlation (spatiotemporal) could result in a prediction for the realized total or mean that is more precise than predictions from a spatial model using only counts from the most recent survey year. 

Though the framework of the motivation is given with an example on moose surveys, this type of analysis could be useful for many examples involving prediction in a finite region with spatial sites that are surveyed regularly.

\subsection{Background}

* Add paragraph about background of spatiotemporal models

Prediction for a total, a subset of the total, or a mean in a finite number of spatial locations should incorporate a finite population correction to the variance of the predictor [@ver2008spatial; @higham2021adjusting]. In the context of ecological monitoring in spatiotemporal prediction, we are often most interested in predicting the total abundance for the most recent year of the survey. In this case, the finite population correction should adjust based on the number of sites surveyed in the current year of the survey, so that, for example, the prediction variance is zero if all sites in the current year are sampled.


The rest of this paper is organized as follows. In Section \ref{section:Methods}, we couple spatiotemporal modeling with finite population prediction to develop the Best-Linear-Unbiased-Predictor for any linear function of site abundance, including the total abundance across all sites. In Section \ref{section:Application}, we apply the predictor to a moose data set in the TOC region of Alaska. In Section \ref{section:Simulation}, we conduct a brief simulation study to examine the properties of the predictor. Finally, in Section \ref{section:Discussion}, we conclude and give directions for future research.

\section{Methods} \label{section:Methods}

We now give details on the development of the predictor for abundance. We first detail the spatiotemporal model. Because of the heavy use of notation in the spatiotemporal model development, we first introduce a purely spatial model (without temporal variability) and a purely temporal model (without spatial variability). We then build the spatiotemporal model and develop a finite population correction factor to give a Best-Linear-Unbiased-Predictor (BLUP) and its prediction variance for total abundance in a given year.

\subsection{Spatial Model} \label{subsection:spatialmodel}

First, we consider a spatial linear model for a response variable $Y_s(\mathbf{s}_{i})$, $i = 1, 2, \ldots, n_{s}$, where the vector $\mathbf{s}_i$ contains the coordinates for the $i^{th}$ spatial site location and $n_s$ is the number of spatial locations. Then, a spatial model for $\mathbf{y}_s(\mathbf{s}_{i})$, a vector of the $Y_s(\mathbf{s}_{i})$, is
\mbox{}
\begin{equation}
\mathbf{y}_s(\mathbf{s}_{i}) = \mathbf{X}_s \bm{\beta}_s + \bm{\epsilon}_s(\mathbf{s}_{i}),
\end{equation}

\noindent
where $\mathbf{X}_s$ is a design matrix for the fixed effects and $\bm{\beta}_s$ is a parameter vector of fixed effects. The error $\bm{\epsilon}_s(\mathbf{s}_{i})$ can be decomposed into spatial error and independent error components:
\mbox{}
\begin{equation}
\label{equation:spatialmodel}
\bm{\epsilon}_s(\mathbf{s}_{i}) = \mathbf{Z}_{s} \bm{\delta} + \mathbf{Z}_{s} \bm{\gamma}.
\end{equation}

\noindent
In equation \ref{equation:spatialmodel}, $\mathbf{Z}_{s}$ is an $n_s \times n_s$ matrix of $0$'s and $1$'s, where the values in a row corresponding to a data point at location $\mathbf{s}_{i}$ are a $1$ in the $i^{th}$ column and a `0` in all other columns. Note that, without temporal replication, $\mathbf{Z}_s$ is the identity matrix so is not necessary to include in equation \ref{equation:spatialmodel}. $\bm{\delta}$ is a random vector independent of $\bm{\gamma}$ with mean $\mathbf{0}$ and covariance $cov(\bm{\delta}) = \sigma^2_{\delta} \mathbf{R}_{s}$, where $\mathbf{R}_s$ is a spatial correlation matrix and $\sigma^2_{\delta}$ is sometimes called the spatial partial sill. $\bm{\gamma}$ is also a random vector with mean $\mathbf{0}$ but has covariance $cov(\bm{\gamma}) = \sigma^2_{\gamma} \mathbf{I}_{s}$, where $\mathbf{I}_s$ is the $n_s \times n_s$ identity matrix and $\sigma^2_{\gamma}$ is sometimes called the spatial nugget.

There are many common parameterizations of $\mathbf{R}_{s}$. One common assumption is to assume the covariance function generating $\mathbf{R}_s$ is stationary and isotropic, depending only on the spatial distance between the data points. For example, the exponential covariance function is defined as follows. For observations at locations $i$ and $i'$ at $h_{ii'}$ distance apart, row $i$ and column $i'$ of $\mathbf{R}_{s}$ is equal to
\mbox{}
\begin{equation}
\label{equation:spatcov}
\text{exp}(-h_{ii'} / \phi),
\end{equation}

\noindent
where $\phi$ is a spatial range parameter controlling the decay rate of the covariance as distance between two data points increases. 

\subsection{Temporal Model} \label{subsection:temporalmodel}

Next, we consider a temporal linear model for a response variable $Y_t(t_j)$, $j = 1, 2, \ldots, n_{t}$, where the vector $t_j$ contains the time for the $j^{th}$ time point and $n_t$ is the number of time points in the data. Then, a temporal model for $\mathbf{y}_t(t_j)$, a vector of the $Y_t(t_j)$, is
\mbox{}
\begin{equation}
\mathbf{y}_t(t_j) = \mathbf{X}_t \bm{\beta}_t + \bm{\epsilon}_t(t_j),
\end{equation}

\noindent
where $\mathbf{X}_t$ is a design matrix for the fixed effects and $\bm{\beta}_t$ is a parameter vector of fixed effects. The error $\bm{\epsilon}_t(t_j)$ can be decomposed into temporal error and independent error components:
\mbox{}
\begin{equation}
\label{equation:temporalmodel}
\bm{\epsilon}_t(t_j) = \mathbf{Z}_{t} \bm{\tau} + \mathbf{Z}_{t} \bm{\eta}.
\end{equation}

\noindent
In equation \ref{equation:temporalmodel}, $\mathbf{Z}_{t}$ is an $n_t \times n_t$ matrix of $0$'s and $1$'s, where the values in a row corresponding to a data point at time point $t_j$ are a $1$ in the $j^{th}$ column and a `0` in all other columns. Note that, without spatial replication, $\mathbf{Z}_t$ is the identity matrix so is not necessary to include in equation \ref{equation:temporalmodel}. $\bm{\tau}$ is a random vector independent of $\bm{\eta}$ with mean $\mathbf{0}$ and covariance $cov(\bm{\tau}) = \sigma^2_{\tau} \mathbf{R}_{t}$, where $\mathbf{R}_t$ is a spatial correlation matrix and $\sigma^2_{\tau}$ is sometimes called the temporal partial sill. $\bm{\eta}$ is also a random vector with mean $\mathbf{0}$ but has covariance $cov(\bm{\eta}) = \sigma^2_{\eta} \mathbf{I}_{t}$, where $\mathbf{I}_t$ is the $n_t \times n_t$ identity matrix and $\sigma^2_{\eta}$ is sometimes called the temporal nugget.

There are many common parameterizations of $\mathbf{R}_{t}$. One common assumption is to assume the covariance function generating $\mathbf{R}_t$ is stationary, depending only on the temporal distance between the data points. For example, the exponential covariance function is defined as follows. For observations at time points $j$ and $j'$ at $m_{jj'}$ units apart, row $j$ and column $j'$ of $\mathbf{R}_{t}$ is equal to
\mbox{}
\begin{equation}
\label{equation:tempcov}
\text{exp}(-m_{jj'} / \rho),
\end{equation}
\noindent
where $\rho$ is a temporal range parameter controlling the decay rate of the covariance as time units between two data points increases. Note that the exponential form of $\mathbf{R}_t$ is equivalent to an AR(1) (CITE) time series model if the time points are equally spaced and the correlation parameter is greater than zero.

\subsection{Spatiotemporal Model}

We now combine the spatial error components and temporal error components to formulate a model for data collected across both space and time. Let $Y(\mathbf{s}_{i}, t_j)$, $i = 1, 2, \ldots, n_{s}$ and $j = 1, 2, \ldots, n_{t}$, be a random variable, where $\mathbf{s}_i$ and $n_s$ are defined in subsection \ref{subsection:spatialmodel} and $t_j$ and $n_t$ are defined in subsection \ref{subsection:temporalmodel}. With each spatial location at each time point, the total number of data points is $n_{s} \cdot n_{t} \equiv N$. Then, a spatiotemporal model for $\mathbf{y}(\mathbf{s}_{i}, t_j)$, a vector of the $Y(\mathbf{s}_{i}, t_j)$, is
\mbox{}
\begin{equation}
\mathbf{y}(\mathbf{s}_{i}, t_j) = \mathbf{X} \bm{\beta} + \bm{\epsilon}(\mathbf{s}_{i}, t_j),
\end{equation}

\noindent
where $\mathbf{X}$ is a design matrix for the fixed effects and $\bm{\beta}$ is a parameter vector of fixed effects. The error $\bm{\epsilon}(\mathbf{s}_{i}, t_j)$ can be decomposed into spatial and temporal components, as in @dumelle2021linear. Perhaps the simplest model would be to simply model the error $\bm{\epsilon}(\mathbf{s}_{i}, t_j)$ by summing the spatial and temporal errors defined in equation \ref{equation:spatialmodel} and equation \ref{equation:temporalmodel}:
\mbox{}
\begin{equation}
\label{equation:sumcovmodel}
\bm{\epsilon}(\mathbf{s}_{i}, t_j) = \mathbf{Z}_{s} \bm{\delta} + \mathbf{Z}_{s} \bm{\gamma} + \mathbf{Z}_{t} \bm{\tau} + \mathbf{Z}_{t} \bm{\eta}.
\end{equation}

With spatial and temporal replication, $\mathbf{Z}_s$ is an $N \times n_s$ matrix while $\mathbf{Z}_t$ is an $N \times n_t$ matrix. However, even when the spatial covariance function generating $\mathbf{Z}_{s} \bm{\delta} + \mathbf{Z}_{s} \bm{\gamma}$ and the temporal covariance function generating $\mathbf{Z}_{t} \bm{\tau} + \mathbf{Z}_{t} \bm{\eta}$ are strictly positive definite, the sum of the spatial and temporal components is not necessarily strictly positive definite (@myers1990variograms). 

A more flexible, given in @dumelle2021linear, is a product-sum linear mixed model
\mbox{}
\begin{equation} \label{equation:model}
\mathbf{y}(\mathbf{s}_{i}, t_j) = \mathbf{X} \bm{\beta} + \mathbf{Z}_{s} \bm{\delta} + \mathbf{Z}_{s} \bm{\gamma} + \mathbf{Z}_t \bm{\tau} + \mathbf{Z}_t \bm{\eta} + \bm{\omega} + \bm{\nu},
\end{equation}

\noindent
In equation \ref{equation:model}, $\bm{\omega}$ is a random vector of length $N$ with mean $\mathbf{0}$ and covariance $cov(\bm{\omega}) = \sigma^2_{\omega} \mathbf{R}_{st}$ where $\mathbf{R}_{st}$ is a spatiotemporal correlation matrix and $\sigma^2_{\omega}$ is sometimes called the spatiotemporal partial sill. $\bm{\nu}$ is also a random vector of length $n$ with mean $\mathbf{0}$ but has covariance $cov(\bm{\nu}) = \sigma^2_{\nu} \mathbf{I}_{st}$, where $\mathbf{I}_{st}$ is the $N \times N$ identity matrix and $\sigma^2_{\nu}$ is sometimes called the spatiotemporal nugget.

A common formulation for $\mathbf{R}_{st}$ is
\mbox{}
\begin{equation*}
\mathbf{R}_{st} \equiv \mathbf{Z}_{s} \mathbf{R}_{s} \mathbf{Z}_{s}' \odot \mathbf{Z}_t \mathbf{R}_t \mathbf{Z}_t',
\end{equation*}

\noindent
where $\odot$ is the Hadamard product operator.

If we assume that $\bm{\delta}$, $\bm{\gamma}$, $\bm{\tau}$, $\bm{\eta}$, $\bm{\omega}$, and $\bm{\nu}$ are mutually independent of each other, then 

\begin{equation}
\label{equation:var}
var(\mathbf{y}) \equiv \bm{\Sigma} = \sigma^2_{\delta} \mathbf{Z}_{s} \mathbf{R}_{s} \mathbf{Z}_{s}' + \sigma^2_{\gamma} \mathbf{Z}_{s} \mathbf{I}_{s} \mathbf{Z}_{s}' + \sigma^2_{\tau} \mathbf{Z}_t \mathbf{R}_t \mathbf{Z}_t'+ \sigma^2_{\eta} \mathbf{Z}_t \mathbf{I}_t \mathbf{Z}_t' + \sigma^2_{\omega} \mathbf{R}_{st} + \sigma^2_{\nu} \mathbf{I}_{st}.
\end{equation}

<!-- Just need MVN for estimation (model itself does not require it) -->
Note that the model in equation \ref{equation:model} does not have any distributional assumptions: we only need to specify the mean and variance of $\mathbf{y}$. However, if we also assume that $\mathbf{y}$ is multivariate normal (with mean $\mathbf{X} \bm{\beta} \equiv \bm{\mu}$ and variance $\bm{\Sigma}$ (Equation \ref{equation:var})), then all model parameters can be easily estimated with Maximum Likelihood or Restricted Maximum Likelihood. 

\subsection{Finite Population Kriging}

The model in equation \ref{equation:model} is for the $N$-length vector $\mathbf{y}$. However, often we do not have the resources to sample or observe every spatial site in every year. Throughout this section, let the subscript $o$ denote observations that were observed (both past and present), the subscript $u$ denote observations that were unobserved, and the subscript $a$ denote all observations. Then, we can re-order the response vector so that
\mbox{}
\begin{equation}
\mathbf{y}_a = [\mathbf{y}_u', \mathbf{y}_o']'.
\end{equation}

Let $\mathbf{\tilde{y}}_a = [\mathbf{\tilde{y}}_u', \mathbf{\tilde{y}}_o']'$ denote the fixed, realized values of the response variable for one data-generating process. Our primary goal is to use the model developed in equation \ref{equation:model} to predict values for $\mathbf{\tilde{y}}_{u}$ from the observed data in $\mathbf{\tilde{y}}_{o}$. That is, we want to find optimal weights $\mathbf{a}'$ to apply to the observed data $\mathbf{a}' \mathbf{\tilde{y}}_o$, such that $\mathbf{a}' \mathbf{y}_o$ is the Best Linear Unbiased Predictor (BLUP) for $\mathbf{b}_a' \mathbf{y}_a$. For example, if we are interested in the total abundance across all years, then $\mathbf{b}_a$ is a column vector of 1's, so that we are adding up all values of the response for a predictor of total abundance. 

Unbiasedness implies that $E(\mathbf{q'}\mathbf{y}_o) = E(\mathbf{b}_a'\mathbf{y}_a)$ for all $\bm{\beta}$. So, denoting $\mathbf{X}_o$ as the design matrix for sampled sites, $\mathbf{q'} \mathbf{X}_o \bm{\beta}$ = $\mathbf{b'} \mathbf{X} \bm{\beta}$ for every $\bm{\beta}$, implying that $\mathbf{q'} \mathbf{X}_o = \mathbf{b'}_a \mathbf{X}_a$.

The kriging weights are then found by finding $\bm{\lambda}_s$, an $n_o \times 1$ vector, such that
\mbox{}
\begin{equation}
E\{(\mathbf{q'}\mathbf{y}_o - \mathbf{b'}_a \mathbf{y}_a)(\mathbf{q'}\mathbf{y}_o - \mathbf{b'}_a \mathbf{y}_a)\} - E\{(\bm{\lambda'}_o\mathbf{y}_o - \mathbf{b'}_a \mathbf{z}_a)(\bm{\lambda}_o'\mathbf{y}_o - \mathbf{b'}_a \mathbf{y}_a)\}
\end{equation}
\noindent
is greater than 0 for all $\mathbf{q'}$. The prediction equations are

\begin{equation}
\begin{pmatrix}
\bm{\Sigma}_{o, o} & \mathbf{X}_o \\
\mathbf{X}_o' & 0
\end{pmatrix} 
\begin{pmatrix}
\bm{\lambda} \\
m
\end{pmatrix} = 
\begin{pmatrix}
\bm{\Sigma}_{o, o} & \bm{\Sigma}_{o, u} \\
\mathbf{X}_{o}' & \mathbf{X}_{u}'
\end{pmatrix} 
\begin{pmatrix}
\mathbf{b}_{o} \\
\mathbf{b}_{u}
\end{pmatrix},
\end{equation}
\noindent
where again the subscripts $o$ and $u$ denote observed and unobserved data points. For example, letting $n_o$ denote the number of observed data points, $\bm{\Sigma}_{o, o}$ denotes the $n_o \times n_o$ submatrix of $\bm{\Sigma}$ corresponding only to rows and columns of observed data points and $\bm{\Sigma}_{u, o}$ denotes the $(N - n_o) \times n_o$ submatrix of $\bm{\Sigma}$ corresponding to rows of data points that were not observed and columns of observations that were observed Then, the optimal prediction weights $\bm{\lambda}_o$ are an $n_o \times 1$ vector:
\mbox{}
\begin{equation}
\bm{\lambda}_o' = \mathbf{b}_{o}' + \mathbf{b}_{u}' (\bm{\Sigma}_{u, o}\bm{\Sigma}_{o, o}^{-1}) - \mathbf{b}'_{u}(\bm{\Sigma}_{u, o} \bm{\Sigma}_{o, o}^{-1})\mathbf{X}_o(\mathbf{X}_o'\bm{\Sigma}_{o, o}^{-1}\mathbf{X}_o)^{-1}\mathbf{X}_o'\bm{\Sigma}_{o, o}^{-1} + \mathbf{b}_{u}' \mathbf{X}_{u}'(\mathbf{X}_o'\bm{\Sigma}_{o, o}^{-1}\mathbf{X}_o)^{-1}\mathbf{X}_o \bm{\Sigma}_{o, o}^{-1}.
\end{equation}
\noindent
Then, the BLUP for $\mathbf{b}'_a \mathbf{y}_a$ is
\mbox{}
\begin{equation}
\hat{\mathbf{b}'_a \mathbf{y}_a} = \bm{\lambda}_o' \mathbf{\tilde{y}}_o,
\end{equation}
\noindent
with a prediction variance of 
\mbox{}
\begin{equation}
E((\bm{\lambda}_o'\mathbf{y}_o - \mathbf{b}_a'\mathbf{y}_a)(\bm{\lambda}_o'\mathbf{y}_o - \mathbf{b}_a'\mathbf{y}_a)) = \\
\bm{\lambda}_o'\bm{\Sigma}_{o, o}\bm{\lambda}_o - 2 \mathbf{b}_a' \bm{\Sigma}_{a, o} \bm{\lambda}_o + \mathbf{b}_a' \bm{\Sigma}_{a, a} \mathbf{b}_a.
\end{equation}



<!-- which is equivalent to  -->

<!-- $$ -->
<!-- \mathbf{b}_{s}'\mathbf{\tilde{y}}_{s} + \mathbf{b}_{u}' \mathbf{\hat{y}}_{u}, -->
<!-- $$ -->
<!-- where $\mathbf{\hat{y}}_{u} = \bm{\Sigma}_{u, s} \Sigma_{s, s}^{-1} (\mathbf{\tilde{y}}_s - \bm{\hat{\mu}}_s) + \bm{\hat{\mu}}_u$ with $\bm{\hat{\mu}}_s = \mathbf{X}_s \bm{\hat{\beta}}_{GLS}, \bm{\hat{\mu}}_u = \mathbf{X}_u \bm{\hat{\beta}}_{GLS}$. $\bm{\hat{\beta}}_{GLS}$ is the generalized least squares estimator $(\mathbf{X}_s' \bm{\Sigma}_{s, s}^{-1} \mathbf{X}_s)^{-1} \mathbf{X}_s' \bm{\Sigma}_{s, s}^{-1} \mathbf{y}_s$. -->



<!-- site-by-site predictions for the unsampled sites in both the past and the present come from the usual block kriging formulae: -->

<!-- \begin{equation} -->
<!-- \mathbf{\hat{y}}_{u} = \bm{\Sigma}_{u, s} \bm{\Sigma}_{s, s}^{-1}(\mathbf{y}_s - \bm{\hat{\mu}}_s) + \bm{\hat{\mu}}_{u}, -->
<!-- \end{equation} -->
 
A common prediction of interest is the total abundance in the most recent time point of the survey. Then, $\mathbf{b}_a$ is a vector of 1's and 0's, where the $k^{th}$ element of $\mathbf{b}_a$ is a $1$ if the $k^{th}$ element of $\mathbf{y}_a$ is from the most current time point of the survey and the $k^{th}$ element of $\mathbf{b}_a$ is a 0 otherwise. If we order $\mathbf{y}_a$ with the unobserved, past data points first, the unobserved, current data points second, the observed, past data points third, and the observed, current data points fourth, then
\mbox{}
\begin{equation}
\mathbf{b}_a = [\mathbf{b}_{up}^\prime, \mathbf{b}_{uc}', \mathbf{b}_{op}', , \mathbf{b}_{oc}']' = [\mathbf{0}', \mathbf{1}', \mathbf{0}', \mathbf{1}']',
\end{equation}
\noindent
where the subscripts $up$, $uc$, $op$, and $oc$ denote unobserved sites in past years, unobserved sites in current years, observed sites in past years, and observed sites in current years, respectively.

$\bm{\lambda}_o$ can then be rewritten as
\mbox{}
\begin{equation} 
\label{equation:lambdacurrentpred}
\bm{\lambda}_o' = \mathbf{b}_{o}' + \mathbf{b}_{uc}' (\bm{\Sigma}_{uc, o}\bm{\Sigma}_{o, o}^{-1}) - \mathbf{b}'_{uc}(\bm{\Sigma}_{uc, o} \bm{\Sigma}_{o, o}^{-1})\mathbf{X}_o(\mathbf{X}_o'\bm{\Sigma}_{o, o}^{-1}\mathbf{X}_o)^{-1}\mathbf{X}_o'\bm{\Sigma}_{o, o}^{-1} + \mathbf{b}_{uc}' \mathbf{X}_{uc}'(\mathbf{X}_o'\bm{\Sigma}_{o, o}^{-1}\mathbf{X}_o)^{-1}\mathbf{X}_o \bm{\Sigma}_{o, o}^{-1}.
\end{equation}

with a prediction variance of
\mbox{}
\begin{equation}
\label{equation:lambdacurrentvar}
\bm{\lambda}_o'\bm{\Sigma}_{o, o}\bm{\lambda}_o - 2 \mathbf{b}_{c}' \bm{\Sigma}_{c, o} \bm{\lambda}_o + \mathbf{b}_{c}' \bm{\Sigma}_{c, c} \mathbf{b}_{c},
\end{equation}
\noindent
where $c$ denotes observations in the most current time point.

\section{Application} \label{section:Application}

\subsection{Data Description}

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(here)
library(FPSpatioTemp)

data(moose_14_20)

## use most recent stratification
moose_14_20 <- moose_14_20 |>
  mutate(newstrat = if_else(Surveyyear == 2020,
                            true = stratfact, 
                            false = NA_integer_)) |>
  group_by(ID) |> fill(newstrat, .direction = "updown") |>
  ungroup()

moose_df_all <- moose_14_20 |>
  select(totalmoosena, SurveyID, Surveyyear, ID,
         newstrat, xcoords, ycoords, samp_frame) |>
  mutate(yearind = if_else(Surveyyear == 2020 & samp_frame == 1,
                           true = 1, false = 0)) |>
  ungroup()


moose_df_merge <- moose_df_all |> filter(yearind == 1) |> select(ID)
moose_final_all <- semi_join(moose_df_all, moose_df_merge)

## nspat unique spatial points and ntime unique time points.
nspat <- nrow(moose_final_all) / length(unique(moose_final_all$Surveyyear))
ntime <- nrow(moose_final_all) / nrow(unique(cbind(moose_final_all$xcoords, moose_final_all$ycoords)))
```

```{r tokplot, fig.cap = "\\label{fig:tokplot} A map of the Taylor Corridor in the TOK region of Alaska.", out.width = "50%"}
library(here)
knitr::include_graphics(here("inst/fpspatiotemp_manu/20E_survey_area_overview.jpg"))
```

Abundance surveys are performed in the Taylor Corridor of the TOK region of Alaska annually (Figure \ref{fig:tokplot}). In particular, surveys were conducted every year from 2014 through 2020, except for the year 2016, during which there was not sufficient snow cover to perform a survey. There are a total of `r nspat` unique spatial locations, which we refer to as "sites," and a total of `r ntime` unique time points in the data set, including the missing year of 2016. 

```{r, results = "hide"}
moose_final_all |> group_by(Surveyyear) |>
  summarise(sum(!is.na(totalmoosena)))
moose_final_all |> group_by(ID) |>
  summarise(n_obs = sum(!is.na(totalmoosena))) |>
  arrange(n_obs)
```

In each year of the survey, an aerial team of biologists selects some of the `r nspat` sites to survey. The number of sites in the sampling frame that are selected varies from a low of 76 in the year 2019 to a high of 90 in the year 2020. Throughout the `r ntime` unique time points, some sites are surveyed as many as four or five different times while others are never surveyed. 

```{r, results = "hide"}
moose_final_all |> group_by(Surveyyear, newstrat) |>
  summarise(ncount = n())
```

```{r}
library(sf)
library(here)
shp <- read_sf(here("inst/ADFG_Taylor_Corridor/20E_Taylor_corridor_SUs.shp"))

ggplot(data = shp) +
  geom_sf() +
  theme_void()

moose_final_2020 <- moose_final_all ##|> filter(Surveyyear == 2020)
moose_shp_2020 <- left_join(shp, moose_final_2020, by = "ID")

ggplot(data = moose_shp_2020) +
  geom_sf(aes(fill = totalmoosena)) +
  facet_wrap( ~Surveyyear) +
  theme_void() +
  scale_fill_viridis_c()
```

Before each the survey begins in each year, biologists stratify the sites into a `"HIGH"` stratum and a `"LOW"` stratum. There are 230 sites in the `"HIGH"` stratum while there are 151 sites in the `"LOW"` stratum. A map of the sites in the TOK region is given in Figure (make figure and put in figure number).

\subsection{Model Fitting} \label{subsection:modelfit}

We fit the product-sum covariance model defined in equation \ref{equation:model} using REML, with stratum as a covariate in the design matrix, an exponential spatial correlation structure defined in \ref{equation:spatcov}, and an exponential temporal correlation structure defined in \ref{equation:tempcov}. Table \ref{paramest} gives the estimated parameters from the model fit.

<!-- The predicted total abundance is moose with a 95% prediction interval of moose. -->


```{r, echo = FALSE, eval = TRUE, cache = TRUE}
## using stratum as a predictor
moose_final_all <- moose_final_all |>
  mutate(allpred_wts = 1) |>
  mutate(predwts2016 = if_else(Surveyyear == 2016,
                               true = 1, 
                               false = 0))
fit_obj_all <- stlmfit(formula = totalmoosena ~ newstrat,
                       data = moose_final_all,
                       xcoord = "xcoords", ycoord = "ycoords",
                       tcoord = "Surveyyear")
fixed_vec <- round(fit_obj_all$fixed_parms, 2)
cov_vec <- round(fit_obj_all$cov_parms, 2)
tab <- cov_vec |>
  as.matrix() |>
  t()
```

```{r, results = "hide"}
colnames(tab) <- c("$\\hat{\\sigma}^2_{\\delta}$",
                   "$\\hat{\\sigma}^2_{\\gamma}$",
                   "$\\hat{\\phi}$",
                   "$\\hat{\\sigma}^2_{\\tau}$",
                   "$\\hat{\\sigma}^2_{\\eta}$",
                   "$\\hat{\\rho}$",
                   "$\\hat{\\sigma}^2_{\\omega}$",
                   "$\\hat{\\sigma}^2_{\\nu}$") 
library(xtable)
xtable(tab, digits = 1, caption = "Table of estimated covariance parameters in the model.", label = "paramest") |>
  print(sanitize.colnames.function = identity)
```

\begin{table}[ht]
\centering
\begin{tabular}{rrrrrrrrr}
  \hline
 & $\hat{\sigma}^2_{\delta}$ & $\hat{\phi}$ & $\hat{\sigma}^2_{\gamma}$ & $\hat{\sigma}^2_{\tau}$ & $\hat{\rho}$ & $\hat{\sigma}^2_{\eta}$ & $\hat{\sigma}^2_{\omega}$ & $\hat{\sigma}^2_{\nu}$ \\ 
  \hline
 & 16.9 & 4.44 & 3.8 & 0.9 & 2.29 & 0.2 & 30.8 & 24.0 \\ 
   \hline
\end{tabular}
\caption{Table of estimated covariance parameters in the model.} 
\label{paramest}
\end{table}

To help interpret what some of these fitted covariance parameter estimates mean, we can construct a fitted covariance plot (Figure \ref{fig:covplot}). Note that the centroids of two sites directly adjacent to one another are about 4 units apart. So, we see from Figure \ref{fig:covplot} that the covariance between random response values from sites that are adjacent is estimated to be about 20 units if the response values are in the same year. The covariance between random responses values from adjacent sites is estimated to be about 10 units if the response values are 6 years apart. As the spatial distance between two sites increases, the covariance between the response values decreases to 0. In fact, the model estimates that, no matter what the time distance is, when two response values are 20 or more units apart, the covariance is nearly 0 units.

The estimated vector of fixed effects, using `"HIGH"` as the reference group, is $\bm{\beta}$ = (`r fixed_vec[1]`, `r fixed_vec[2]`). Therefore the overall mean for sites in the `"HIGH"` stratum is estimated to be `r fixed_vec[1]` moose while the overall mean for sites in the `"LOW"` stratum is estimated to be `r fixed_vec[1] + fixed_vec[2]` moose.


```{r covplot, fig.cap = "\\label{fig:covplot} Estimated covariance from the fitted parameters in a product-sum model."}
# moose_14 <- moose_df_all |> filter(Surveyyear == 2014)
# dist_mat <- as.matrix(dist(cbind(moose_14$xcoords, moose_14$ycoords)))
# min(dist_mat[dist_mat != 0])

## if using Mike's functions, need to adjust for the effective range
## parameterization that he uses.

## need to fix spatial x-axis version but I kind of like the temporal one
## better anyway.

plot_cov(fit_obj_all, sp_epstol = c(0.2, 4, 20, Inf),
         t_epstol = c(0.2, 2, 6),
         xaxis_var = "temporal")
```


fact that cov > 0 when temporal distance is 6 for some sites implies that going back further in time could help improve precision even further.

\subsection{Prediction}

```{r, results = "hide"}
pred_obj_all <- predict(object = fit_obj_all, wtscol = "yearind")

prediction_all <- pred_obj_all$totalpred
predvar_all <- pred_obj_all$predvar
lb_all <- pred_obj_all$lb
ub_all <- pred_obj_all$ub
tab_stlmfit_all <- cbind(prediction_all, sqrt(predvar_all),
                          lb_all, ub_all)
library(xtable)
xtable(tab_stlmfit_all, digits = 0)
```

We now use the model in subsection \ref{subsection:modelfit} to predict the total abundance across all sites in the year 2020, the most recent year of the survey. Plugging in estimates of the covariance parameters into equations \ref{equation:lambdacurrentpred} and \ref{equation:lambdacurrentvar} and letting elements of $\mathbf{b}_a$ be 1's for data points in 2020 and 0's otherwise, we obtain a prediction of `r round(as.numeric(prediction_all), 0)` moose and a standard error of `r round(as.numeric(sqrt(predvar_all)), 0)` moose. A 90% normal-based prediction interval for the total abundance in 2020 is (`r round(lb_all, 0)`, `r round(ub_all, 0)`) moose. Sitewise predictions for sites in 2020 are given in the map in Figure \ref{fig:sitepredmap}.

```{r, fig.cap = "\\label{fig:sitepredmap} A map of the predictions for the sites in the year 2020."}
pred_obj_map <- predict(object = fit_obj_all, wtscol = "allpred_wts")
moose_shp_preds <- left_join(shp, pred_obj_map$data)

# ggplot(data = moose_shp_preds) +
#   geom_sf(aes(fill = predictions_)) +
#   facet_wrap( ~ Surveyyear, nrow = 2) +
#   theme_void() +
#   scale_fill_viridis_c()

moose_shp_preds_2020 <- moose_shp_preds |> filter(Surveyyear == 2020)
ggplot(data = moose_shp_preds_2020) +
  geom_sf(aes(fill = predictions_)) +
  theme_void() +
  scale_fill_viridis_c() +
  geom_point(data = moose_shp_preds_2020 |> filter(ind_sa == 1), aes(x = CentoidX, y = CentroidY), size = 0.3, colour = grey(.5))
```

For comparison, we use the spatial `sptotal` package [@higham2021sptotal] to compute the prediction for the total abundance of moose in the year 2020 [@ver2008spatial]. We also use the standard simple random sampling estimator $\bar{y} \cdot \frac{n_s}{n_{o}}$, where $\bar{y}$ is the sample mean for the data points in 2020, $n_s$ is the total number of sites in 2020, and $n_o$ is the number of observed data points in 2020. The simple random sampling estimator has a standard error for the total abundance of $n_s^2 \cdot \frac{\hat{\sigma}^2}{n_o} \cdot (1 - \frac{n_o}{n_s})$.

```{r}
moose_final_2020 <- moose_final_all |>
  dplyr::filter(Surveyyear == 2020)

library(sptotal)
fit_obj_2020 <- slmfit(formula = totalmoosena ~ newstrat,
                       data = moose_final_2020,
                       xcoordcol = "xcoords", ycoordcol = "ycoords",
                       estmethod = "ML")
pred_obj_2020 <- predict(fit_obj_2020)
tab_sptotal <- cbind(pred_obj_2020$FPBK_Prediction, sqrt(pred_obj_2020$PredVar),
                     pred_obj_2020$conf_bounds[1], pred_obj_2020$conf_bounds[2])

pred_sptotal <- round(as.vector(pred_obj_2020$FPBK_Prediction), 0)
se_sptotal <- round(as.vector(sqrt(pred_obj_2020$PredVar)), 0)
```

```{r}
mean_srs <- mean(moose_final_2020$totalmoosena, na.rm = TRUE) 
N_srs <- nrow(moose_final_2020)
n_srs <- sum(!is.na(moose_final_2020$totalmoosena))
var_srs <- var(moose_final_2020$totalmoosena, na.rm = TRUE)

pred_srs <- round(mean_srs * N_srs, 0)
se_srs <- round(sqrt(N_srs ^ 2 * var_srs / n_srs * (1 - n_srs / N_srs)), 0)
```

For the purely spatial model, the prediction for the total number of moose in 2020 in the region is `r pred_sptotal` moose with a standard error of `r se_sptotal` moose. For the simple random sampling estimator, the estimated total number of moose in 2020 in the region is `r pred_srs` with a standard error of `se_srs`. While the predictions for the total are similarly across the three methods, we see that the spatiotemporal model is most efficient ($SE$ = `r round(as.numeric(sqrt(predvar_all)), 0)`). We lose some of that efficiency by ignoring the data in previous years but still assuming that the data are spatially correlated (as in the model fit with `sptotal`). And, we lose even more efficiency by taking advantage of neither the temporal nor the spatial correlation (as in the simple random sample estimator).

```{r, eval = FALSE}
pred_sptotal <- pred_obj_2020$Pred_df |>
  select(ID, totalmoosena_pred_count, totalmoosena_predvar_count)

moose_shp_allpreds <- left_join(moose_shp_preds_2020, pred_sptotal) |>
  mutate(pred_diffs = predictions_ - totalmoosena_pred_count)
ggplot(data = moose_shp_allpreds) +
  geom_sf(aes(fill = pred_diffs)) +
  theme_void() +
  scale_fill_viridis_c() +
  geom_point(data = moose_shp_preds_2020 |> filter(ind_sa == 1), aes(x = CentoidX, y = CentroidY), size = 0.3, colour = grey(.5))
```

```{r}
pred_obj_2016 <- predict(object = fit_obj_all, wtscol = "predwts2016")
pred_2016 <- round(as.vector(pred_obj_2016$totalpred), 0)
se_2016 <- round(sqrt(as.vector(pred_obj_2016$predvar)), 0)
lb_2016 <- round(pred_obj_2016$lb)
ub_2016 <- round(pred_obj_2016$ub)
```

<!-- Another idea: use this model to predict the abundance of moose at the sampled sites in 2021 (to see if the interval covers and to see how close the predictor is). -->



<!-- Other Information: 2013: separate area -->
<!-- 2016: no snow -->

<!-- -2013: two regions surveyed -->
<!-- 2014- pare it down to the smaller area from the larger area previously -->
<!-- 2019- took two areas from 2004 - 2014 plus what was added on after 2014 -->
<!-- 2020- 2014-2018 -->
<!-- 2021- 2014-2018 area (planned) -->

 <!-- From 2004 - 2012, two regions were surveyed on an alternating year basis (e.g. Region 1 was surveyed in 2004, Region 2 in 2005, Region 1 in 2006, etc.). In 2013, both of these regions were surveyed. From 2014 - 2018, the the two "alternating year regions" were combined into one single survey region that was a subset of these two regions. This smaller region was thought to be of the highest importance for moose abundance prediction. The 2014 - 2018 region also included a small region that was not part of the 2004 - 2013 surveys. 2016 did not have a survey because there was not sufficient snow cover. The 2019 survey took the survey area from 2004 - 2013 and added the small region that was added in the 2014 - 2018 surveys. 2020 reverted to the 2014 - 2018 survey area, and 2021 is planned to also survey that same area.  -->

<!-- In summary, there is a subset of sites that was sampled from 2004 - 2020, but, of most interest is probably the area that has been surveyed every year since 2014 (except for the year 2016, when no survey was done). -->

```{r, message = FALSE, warning = FALSE}
moose_temp_high <- moose_14_20 |> dplyr::filter(newstrat == "HIGH")

## keep only variables that are necessary for analysis
moose_df_high <- moose_temp_high |>
  select(totalmoosena, SurveyID, Surveyyear, ID,
         newstrat, xcoords, ycoords, samp_frame)

## create a variable for what values we want added up for
## abundance
moose_df_high <- moose_df_high |>
  mutate(yearind = if_else(Surveyyear == 2020 & samp_frame == 1,
                           true = 1, false = 0)) |> ungroup()

moose_df_merge <- moose_df_high |> filter(yearind == 1) |> select(ID)
moose_final_high <- semi_join(moose_df_high, moose_df_merge)

## nspat unique spatial points and ntime unique time points.
nspat <- nrow(moose_final_high) / length(unique(moose_final_high$Surveyyear))
ntime <- nrow(moose_final_high) / nrow(unique(cbind(moose_final_high$xcoords, moose_final_high$ycoords)))
```

```{r}
moose_temp_low <- moose_14_20 |> dplyr::filter(newstrat == "LOW")

## keep only variables that are necessary for analysis
moose_df_low <- moose_temp_low |>
  select(totalmoosena, SurveyID, Surveyyear, ID,
         newstrat, xcoords, ycoords, samp_frame)

## create a variable for what values we want added up for
## abundance
moose_df_low <- moose_df_low |>
  mutate(yearind = if_else(Surveyyear == 2020 & samp_frame == 1,
                           true = 1, false = 0)) |> ungroup()

moose_df_merge_low <- moose_df_low |> filter(yearind == 1) |> select(ID)
moose_final_low <- semi_join(moose_df_low, moose_df_merge_low)

## n unique spatial points and n unique time points.
nspat_low <- nrow(moose_final_low) / length(unique(moose_final_low$Surveyyear))
ntime_low <- nrow(moose_final_low) / nrow(unique(cbind(moose_final_low$xcoords, moose_final_low$ycoords)))
```




```{r, cache = TRUE}
fit_obj_high <- stlmfit(formula = totalmoosena ~ 1,
                        data = moose_final_high,
                        xcoord = "xcoords",
                        ycoord = "ycoords",
                        tcoord = "Surveyyear")
```

```{r, results = "hide"}
pred_obj_high <- predict(object = fit_obj_high,
                         wtscol = "yearind")

prediction_high <- pred_obj_high$totalpred
predvar_high <- pred_obj_high$predvar
lb_high <- pred_obj_high$lb
ub_high <- pred_obj_high$ub
tab_stlmfit_high <- cbind(prediction_high, sqrt(predvar_high),
                          lb_high, ub_high)
library(xtable)
xtable(tab_stlmfit_high, digits = 0)
```

```{r, cache = TRUE}
fit_obj_low <- stlmfit(formula = totalmoosena ~ 1,
                       data = moose_final_low,
                       xcoord = "xcoords",
                       ycoord = "ycoords",
                       tcoord = "Surveyyear")
```

```{r, results = "hide"}
pred_obj_low <- predict(object = fit_obj_low, wtscol = "yearind")

prediction_low <- pred_obj_low$totalpred
predvar_low <- pred_obj_low$predvar
lb_low <- pred_obj_low$lb
ub_low <- pred_obj_low$ub
tab_stlmfit_low <- cbind(prediction_low, sqrt(predvar_low),
                          lb_low, ub_low)
xtable(tab_stlmfit_low, digits = 0)
```

```{r, results = "hide"}
unlist(fit_obj_high$parms)
unlist(fit_obj_low$parms)
```

```{r, fig.keep = "none"}
plot_sp(fit_obj_high$data$xcoords, fit_obj_high$data$ycoords,
        fit_obj_high$data$Surveyyear, fit_obj_high$data$totalmoosena)
plot_sp(fit_obj_low$data$xcoords, fit_obj_low$data$ycoords,
        fit_obj_low$data$Surveyyear, fit_obj_low$data$totalmoosena)
plot_t(fit_obj_high$data$xcoords, fit_obj_high$data$ycoords,
        fit_obj_high$data$Surveyyear, fit_obj_high$data$totalmoosena)
plot_t(fit_obj_low$data$xcoords, fit_obj_low$data$ycoords,
        fit_obj_low$data$Surveyyear, fit_obj_low$data$totalmoosena)
```

```{r}
pred_total <- tab_stlmfit_low[1, 1] + tab_stlmfit_high[1, 1]
pred_var <- sqrt(tab_stlmfit_low[1, 2] ^ 2 +
                   tab_stlmfit_high[1, 2] ^ 2)
pis <- pred_total + c(-1, 1) * 1.96 * 65.415
```


```{r, results = "hide"}
## sptotal on HIGH stratum
moose_final_high_2020 <- moose_final_high |>
  dplyr::filter(Surveyyear == 2020)

library(sptotal)
fit_obj_2020_high <- slmfit(formula = totalmoosena ~ 1,
                       data = moose_final_high_2020,
                       xcoordcol = "xcoords", ycoordcol = "ycoords",
                       estmethod = "ML")
pred_obj_2020_high <- predict(fit_obj_2020_high)
tab_sptotal_high <- cbind(pred_obj_2020_high$FPBK_Prediction, sqrt(pred_obj_2020_high$PredVar),
                     pred_obj_2020_high$conf_bounds[1], pred_obj_2020_high$conf_bounds[2])
tab_combined_high <- rbind(tab_stlmfit_high, tab_sptotal_high)
row.names(tab_combined_high) <- c("stlmfit", "sptotal")
colnames(tab_combined_high) <- c("prediction", "se", "90% lb", "90% ub")

## sptotal on LOW stratum
moose_final_low_2020 <- moose_final_low |>
  dplyr::filter(Surveyyear == 2020)

library(sptotal)
fit_obj_2020_low <- slmfit(formula = totalmoosena ~ 1,
                       data = moose_final_low_2020,
                       xcoordcol = "xcoords", ycoordcol = "ycoords",
                       estmethod = "ML")

pred_obj_2020_low <- predict(fit_obj_2020_low)
tab_sptotal_low <- cbind(pred_obj_2020_low$FPBK_Prediction, sqrt(pred_obj_2020_low$PredVar),
                     pred_obj_2020_low$conf_bounds[1], pred_obj_2020_low$conf_bounds[2])
tab_combined_low <- rbind(tab_stlmfit_low, tab_sptotal_low)
row.names(tab_combined_low) <- c("stlmfit", "sptotal")
colnames(tab_combined_low) <- c("prediction", "se", "90% lb", "90% ub")


pred_sptotal <- pred_obj_2020_high$FPBK_Prediction + pred_obj_2020_low$FPBK_Prediction
se_sptotal <- sqrt(pred_obj_2020_high$PredVar + pred_obj_2020_low$PredVar)
pis_sptotal <- pred_sptotal[1, 1] +
  c(-1, 1) * 1.96 * se_sptotal[1, 1]
```

<!-- Moose surveys in the TOC region were historically analyzed without explicitly using any data from surveys in past years. Therefore, we compare the spatiotemporal prediction and prediction interval with a spatial model fit with the $\texttt{sptotal}$ package using only the data from the year 2020. The prediction total abundance is `r round(pred_sptotal, 0)` moose with a 95% prediction interval of (`r round(pis_sptotal[1], 0)`, `r round(pis_sptotal[2], 0)`) moose. We see that the predictions are somewhat similar, but that, because the strictly spatial analysis ignores information from past years, the prediction interval for the spatiotemporal analysis is more narrow. -->

\section{Simulation} \label{section:Simulation}

* possibly include `sptotal` (on current year only) and SRS (on current year only) as reference comparisons.

For a preliminary simulation, we simulate a response vector $\mathbf{y}$ on a $20 \times 20$ grid of 400 spatial sites and 10 time points. $\mathbf{y}$ is multivariate normal with mean $\mathbf{10}$ and covariance $\bm{\Sigma}$ defined in equation \ref{equation:var} with the following covariance parameters:

<!-- \begin{table}[ht] -->
<!-- \centering -->
<!-- \begin{tabular}{rrrrrrrrr} -->
<!--   \hline -->
<!--  & $\sigma^2_{\delta}$ & $\phi$ & $\hat{\sigma}^2_{\gamma}$ & $\hat{\sigma}^2_{\tau}$ & $\hat{\rho}$ & $\hat{\sigma}^2_{\eta}$ & $\hat{\sigma}^2_{\omega}$ & $\hat{\sigma}^2_{\nu}$ \\  -->
<!--   \hline -->
<!-- 0.9 & 5 & 0.1 & 0.7 & 0.8 & 0.3 & 0.4 & 30.8 & 24.0 \\  -->
<!--    \hline -->
<!-- \end{tabular} -->
<!-- \caption{Table of estimated covariance parameters in the model.}  -->
<!-- \label{simparms} -->
<!-- \end{table} -->

```{r}
library(tidyverse)

files <- list.files(here("inst/simulations/raw_sims"), full.names = TRUE)

sims_readin <- map(files, read_csv, col_names = FALSE)
sims_df <- bind_rows(sims_readin) 

names(sims_df) <- c("pred", "se", "lb", "ub", "truetotal",
                    "parms.yo",
                    "parms.sigma_parsil_spat",
                    "parms.range",
                    "parms.sigma_nugget_spat",
                    "parms.sigma_parsil_time",
                    "parms.rho",
                    "parms.sigma_nugget_time",
                    "parms.sigma_nugget_spacetime",
                    "parms.sigma_parsil_spacetime",
                    "conf_ind")
ggplot(data = sims_df, aes(x = (pred - truetotal))) +
  geom_histogram(colour = "black", fill = "white", bins = 15)

ggplot(data = sims_df, aes(x = parms.range)) +
  geom_histogram(colour = "black", fill = "white", bins = 15)
```


The spatiotemporal process is simulated as a product-sum model with an exponential spatial correlation structure and an exponential temporal correlation structure with the following parameters

The mean is

* $\beta$ = 10.

The spatial parameters are

* $\sigma^2_{\delta}$ = 0.9, 
* $\sigma^2_{\gamma}$ = 0.1,
* $\phi$ = 5.

The temporal parameters are

* $\sigma^2_{\tau}$ = 0.7, 
* $\sigma^2_{\eta}$ = 0.3,
* $\rho$ = 0.8.

And, the spatiotemporal nugget is

* $\sigma^2_{\nu}$ = 0.4.

The sample size $n$ is 100 (of the 500 total data points). For 100 iterations, the percentage of 90% prediction intervals that covered the true total was 81%. 

There are a few plausible reasons for this low coverage:

Hampering investigation of this is the fact that the simulations take a long time to run. The `stmodel` package will be very helpful for this, as we can replace the slow code for fitting the spatiotemporal model with faster code from the package.

```{r, echo = FALSE, results = "hide"}
library(here)
sim_res <- read_csv(here("inst", "simulations", "sim_output.csv"))

sim_res |> summarise(coverage = mean(conf_ind),
                            rmspe = sqrt(sum((pred - truetotal) ^ 2)),
                            medci = median(ub - lb),
                            meanse = mean(se))
```

\section{Discussion} \label{section:Discussion}

* substantial reduction of se in the application (and, presumably, the simulations).

* normal-based-related limitations

* Bayesian approach, and its potential flaws

* possible extension to imperfect detection

* forecasting potential

* take-home message: monitoring programs that use regularly surveys might consider incorporating time into their analysis to improve precision of predictors.


